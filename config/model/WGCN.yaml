fm_embedding_size: 4
mf_embedding_size: 64
n_layers: 2
learning_rate: 0.01
reg_weight: 1e-02
mlp_hidden_size: [64, 64, 64]
dropout_prob: 0.1
eval_batch_size: 65536