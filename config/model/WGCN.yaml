fm_embedding_size: 4
mf_embedding_size: 64
n_layers: 2
reg_weight: 1e-04
mlp_hidden_size: [64, 64, 64]
dropout_prob: 0.1
eval_batch_size: 65536